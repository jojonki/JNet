{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import argparse\n",
    "from nltk.tokenize import word_tokenize\n",
    "from process_data import save_pickle, load_pickle, load_task, load_glove_weights, to_var, make_word_vector\n",
    "from word_embedding import WordEmbedding\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.argv = ['a.py']\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', type=int, default=8, help='input batch size')\n",
    "parser.add_argument('--embd_size', type=int, default=100, help='word embedding size')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ./pickles/train_data.pickle\n",
      "load ./pickles/dev_data.pickle\n",
      "vocab size 123295\n",
      "ans size 78025\n",
      "context maxlen: 766\n",
      "query maxlen: 60\n",
      "load ./pickles/glove_embd.pickle\n"
     ]
    }
   ],
   "source": [
    "# train_data = load_task('./dataset/train-v1.1.json')\n",
    "train_data = load_pickle('./pickles/train_data.pickle')\n",
    "# dev_data = load_task('./dataset/dev-v1.1.json')\n",
    "dev_data = load_pickle('./pickles/dev_data.pickle')\n",
    "data = train_data+dev_data\n",
    "vocab, vocab_a = set(), set()\n",
    "for ctx, q_id, query,answer in data:\n",
    "    vocab |= set(ctx + query)# + answer)\n",
    "    vocab_a |= set(answer)\n",
    "    \n",
    "vocab = list(sorted(vocab))\n",
    "vocab_a = list(sorted(vocab_a))\n",
    "w2i = dict((w, i) for i, w in enumerate(vocab, 0))\n",
    "i2w = dict((i, w) for i, w in enumerate(vocab, 0))\n",
    "a2i = dict((w, i) for i, w in enumerate(vocab_a, 0))\n",
    "i2a = dict((i, w) for i, w in enumerate(vocab_a, 0))\n",
    "args.vocab_size = len(vocab)\n",
    "args.ans_size = len(vocab_a)\n",
    "print('vocab size', len(vocab))\n",
    "print('ans size', len(vocab_a))\n",
    "\n",
    "ctx_maxlen = max([len(c) for c, _, _, _ in data])\n",
    "query_maxlen = max([len(q) for _, _, q, _ in data])\n",
    "print('context maxlen:', ctx_maxlen)\n",
    "print('query maxlen:', query_maxlen)\n",
    "\n",
    "glove_embd = load_pickle('./pickles/glove_embd.pickle')\n",
    "# glove_embd = torch.from_numpy(load_glove_weights('./dataset', args.embd_size, len(vocab), w2i)).type(torch.FloatTensor)\n",
    "# save_pickle(glove_embd, './pickles/glove_embd.pickle')\n",
    "args.pre_embd = glove_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch 0\n",
      "context torch.Size([16, 766])\n",
      "query torch.Size([16, 60])\n",
      "context_embd torch.Size([16, 766, 100])\n",
      "context_gru torch.Size([16, 766, 200])\n",
      "query embd torch.Size([16, 60, 100])\n",
      "query gru torch.Size([16, 60, 200])\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "class JNet(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(JNet, self).__init__()\n",
    "        self.embd_size = args.embd_size\n",
    "        \n",
    "        self.embd = WordEmbedding(args)\n",
    "        self.ctx_birnn = nn.GRU(self.embd_size, self.embd_size, bidirectional=True, dropout=0.2)\n",
    "        self.query_birnn = nn.GRU(self.embd_size, self.embd_size, bidirectional=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "    def forward(self, context, query):\n",
    "        print('context', context.size())\n",
    "        print('query', query.size())\n",
    "        context_data = self.embd(context)\n",
    "        print('context_embd', context_data.size())\n",
    "        context_data, _h = self.ctx_birnn(context_data)\n",
    "        print('context_gru', context_data.size())\n",
    "        \n",
    "        query_data = self.embd(query)\n",
    "        print('query embd', query_data.size())\n",
    "        query_data, _h = self.ctx_birnn(query_data)\n",
    "        print('query gru', query_data.size())\n",
    "        \n",
    "\n",
    "        \n",
    "def train(model, optimizer=None, n_epoch=1, batch_size=16):\n",
    "    for epoch in range(n_epoch):\n",
    "        print('---Epoch', epoch)\n",
    "        for i in range(0, len(data)-batch_size, batch_size): # TODO shuffle, last elms\n",
    "            batch_data = data[i:i+batch_size]\n",
    "            c = [d[0] for d in batch_data]\n",
    "            q = [d[2] for d in batch_data]\n",
    "            context_var = make_word_vector(c, w2i, ctx_maxlen)\n",
    "            query_var = make_word_vector(q, w2i, query_maxlen)\n",
    "            ans_var = to_var(torch.LongTensor([a2i[d[3][0]] for d in batch_data]))#.squeeze()) #\n",
    "            model(context_var, query_var)\n",
    "            break\n",
    "        break\n",
    "            \n",
    "#             model.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "    \n",
    "model = JNet(args)\n",
    "# if torch.cuda.is_available():\n",
    "#     model.cuda()\n",
    "# print(model)\n",
    "# for p in model.parameters():\n",
    "#     print(p)\n",
    "# optimizer = torch.optim.Adadelta(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=0.5, weight_decay=0.999)\n",
    "train(model)#, optimizer)\n",
    "print('fin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
