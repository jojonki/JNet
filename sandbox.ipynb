{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import argparse\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from process_data import save_pickle, load_pickle, load_task, load_glove_weights, to_var, make_word_vector, make_one_hot\n",
    "from word_embedding import WordEmbedding\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.argv = ['a.py']\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', type=int, default=8, help='input batch size')\n",
    "parser.add_argument('--embd_size', type=int, default=100, help='word embedding size')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_data import save_pickle, load_pickle, load_task, load_glove_weights, to_var, make_word_vector, make_one_hot\n",
    "train_data, train_ctx_maxlen = load_task('./dataset/train-v1.1.json')\n",
    "# save_pickle(train_data, './pickles/train_data.pickle')\n",
    "# train_data = load_pickle('./pickles/train_data.pickle')\n",
    "dev_data, dev_ctx_maxlen = load_task('./dataset/dev-v1.1.json')\n",
    "# save_pickle(dev_data, './pickles/dev_data.pickle')\n",
    "# dev_data = load_pickle('./pickles/dev_data.pickle')\n",
    "print('N train', len(train_data))\n",
    "print('N dev', len(dev_data))\n",
    "data = train_data+dev_data\n",
    "# ctx_maxlen = max(train_ctx_maxlen, dev_ctx_maxlen)\n",
    "# ctx_maxlen = 4063 #TODO\n",
    "# args.ctx_maxlen = ctx_maxlen\n",
    "# print('context char-level maxlen:', ctx_maxlen)\n",
    "\n",
    "vocab, vocab_a = set(), set()\n",
    "for ctx, _, query,answer, _, _ in data:\n",
    "    vocab |= set(ctx + query)# + answer)\n",
    "    vocab_a |= set(answer)\n",
    "    \n",
    "vocab = list(sorted(vocab))\n",
    "vocab_a = list(sorted(vocab_a))\n",
    "w2i = dict((w, i) for i, w in enumerate(vocab, 0))\n",
    "i2w = dict((i, w) for i, w in enumerate(vocab, 0))\n",
    "a2i = dict((w, i) for i, w in enumerate(vocab_a, 0))\n",
    "i2a = dict((i, w) for i, w in enumerate(vocab_a, 0))\n",
    "args.vocab_size = len(vocab)\n",
    "args.ans_size = len(vocab_a)\n",
    "print('vocab size', len(vocab))\n",
    "print('ans size', len(vocab_a))\n",
    "\n",
    "ctx_sent_maxlen = max([len(c) for c, _, _, _, _, _ in data])\n",
    "query_sent_maxlen = max([len(q) for _, _, q, _, _, _ in data])\n",
    "print('ctx_sent_maxlen:', ctx_sent_maxlen)\n",
    "print('query_sent_maxlen:', query_sent_maxlen)\n",
    "args.ctx_sent_maxlen = ctx_sent_maxlen\n",
    "args.query_sent_maxlen = query_sent_maxlen\n",
    "args.answer_seq_len = 1 # 2 TODO\n",
    "\n",
    "glove_embd = load_pickle('./pickles/glove_embd.pickle')\n",
    "# glove_embd = torch.from_numpy(load_glove_weights('./dataset', args.embd_size, len(vocab), w2i)).type(torch.FloatTensor)\n",
    "# save_pickle(glove_embd, './pickles/glove_embd.pickle')\n",
    "args.pre_embd = glove_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "def train(model, optimizer, loss_fn, n_epoch=5, batch_size=32):\n",
    "    for epoch in range(n_epoch):\n",
    "        print('---Epoch', epoch)\n",
    "        for i in tqdm(range(0, len(data)-batch_size, batch_size)): # TODO shuffle, last elms\n",
    "            batch_data = data[i:i+batch_size]\n",
    "            c = [d[0] for d in batch_data]\n",
    "            q = [d[2] for d in batch_data]\n",
    "            context_var = make_word_vector(c, w2i, ctx_sent_maxlen)\n",
    "            query_var = make_word_vector(q, w2i, query_sent_maxlen)\n",
    "#             labels = [[d[4][0], d[5][0]] for d in batch_data]\n",
    "            labels = [d[4][0] for d in batch_data]\n",
    "            labels = to_var(torch.LongTensor(labels))\n",
    "            outs = model(context_var, query_var)\n",
    "            outs = outs.view(-1, ctx_sent_maxlen) #(B*M, L)\n",
    "            labels = labels.view(-1) # (B*M)\n",
    "            loss = loss_fn(outs, labels)\n",
    "            if i % (batch_size*10) == 0:\n",
    "                print(loss.data[0])\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             break\n",
    "        \n",
    "        _, preds = torch.max(outs, 1)\n",
    "        ct = 0\n",
    "        for pred, label in zip(preds, labels):\n",
    "            if pred.data[0] == label.data[0]: \n",
    "                ct+=1\n",
    "        print('Acc', ct, '/', len(preds))\n",
    "        break\n",
    "        \n",
    "    \n",
    "model = JNet(args)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "# print(model)\n",
    "# for p in model.parameters():\n",
    "#     print(p)\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adadelta(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=0.5, weight_decay=0.999)\n",
    "train(model, optimizer, loss_fn)\n",
    "print('fin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
