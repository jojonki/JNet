{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import argparse\n",
    "from nltk.tokenize import word_tokenize\n",
    "from process_data import save_pickle, load_pickle, load_task, load_glove_weights, to_var, make_word_vector, make_one_hot\n",
    "from word_embedding import WordEmbedding\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.argv = ['a.py']\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', type=int, default=8, help='input batch size')\n",
    "parser.add_argument('--embd_size', type=int, default=100, help='word embedding size')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ./pickles/train_data.pickle\n",
      "load ./pickles/dev_data.pickle\n",
      "context char-level maxlen: 4063\n",
      "vocab size 123295\n",
      "ans size 78025\n",
      "ctx_sent_maxlen: 766\n",
      "query_sent_maxlen: 60\n",
      "load ./pickles/glove_embd.pickle\n"
     ]
    }
   ],
   "source": [
    "# train_data, train_ctx_maxlen = load_task('./dataset/train-v1.1.json')\n",
    "# save_pickle(train_data, './pickles/train_data.pickle')\n",
    "train_data = load_pickle('./pickles/train_data.pickle')\n",
    "# dev_data, dev_ctx_maxlen = load_task('./dataset/dev-v1.1.json')\n",
    "# save_pickle(dev_data, './pickles/dev_data.pickle')\n",
    "dev_data = load_pickle('./pickles/dev_data.pickle')\n",
    "data = train_data+dev_data\n",
    "ctx_maxlen = max(train_ctx_maxlen, dev_ctx_maxlen)\n",
    "args.ctx_maxlen = ctx_maxlen\n",
    "print('context char-level maxlen:', ctx_maxlen)\n",
    "\n",
    "vocab, vocab_a = set(), set()\n",
    "for ctx, _, query,answer, _, _ in data:\n",
    "    vocab |= set(ctx + query)# + answer)\n",
    "    vocab_a |= set(answer)\n",
    "    \n",
    "vocab = list(sorted(vocab))\n",
    "vocab_a = list(sorted(vocab_a))\n",
    "w2i = dict((w, i) for i, w in enumerate(vocab, 0))\n",
    "i2w = dict((i, w) for i, w in enumerate(vocab, 0))\n",
    "a2i = dict((w, i) for i, w in enumerate(vocab_a, 0))\n",
    "i2a = dict((i, w) for i, w in enumerate(vocab_a, 0))\n",
    "args.vocab_size = len(vocab)\n",
    "args.ans_size = len(vocab_a)\n",
    "print('vocab size', len(vocab))\n",
    "print('ans size', len(vocab_a))\n",
    "\n",
    "ctx_sent_maxlen = max([len(c) for c, _, _, _, _, _ in data])\n",
    "query_sent_maxlen = max([len(q) for _, _, q, _, _, _ in data])\n",
    "print('ctx_sent_maxlen:', ctx_sent_maxlen)\n",
    "print('query_sent_maxlen:', query_sent_maxlen)\n",
    "args.ctx_sent_maxlen = ctx_sent_maxlen\n",
    "args.query_sent_maxlen = query_sent_maxlen\n",
    "\n",
    "glove_embd = load_pickle('./pickles/glove_embd.pickle')\n",
    "# glove_embd = torch.from_numpy(load_glove_weights('./dataset', args.embd_size, len(vocab), w2i)).type(torch.FloatTensor)\n",
    "# save_pickle(glove_embd, './pickles/glove_embd.pickle')\n",
    "args.pre_embd = glove_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch 0\n",
      "torch.Size([16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /pytorch/torch/lib/THNN/generic/ClassNLLCriterion.c:62",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-8536f33f1f4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# optimizer = torch.optim.Adadelta(model.parameters(), lr=0.5, weight_decay=0.999)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-8536f33f1f4e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss_fn, n_epoch, batch_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#             print('out', outs.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         return F.nll_loss(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 132\u001b[0;31m                           self.ignore_index)\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, target, *args)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         getattr(ctx._backend, update_output.name)(ctx._backend.library_state, input, target,\n\u001b[0;32m---> 47\u001b[0;31m                                                   output, *ctx.additional_args)\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /pytorch/torch/lib/THNN/generic/ClassNLLCriterion.c:62"
     ]
    }
   ],
   "source": [
    "class JNet(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(JNet, self).__init__()\n",
    "        self.embd_size = args.embd_size\n",
    "        h_emb = (int)(self.embd_size*0.5)\n",
    "        \n",
    "        self.embd = WordEmbedding(args)\n",
    "        self.ctx_birnn = nn.ModuleList([nn.GRU(self.embd_size, h_emb, bidirectional=True, dropout=0.2) for _ in range(2)])\n",
    "        self.query_birnn = nn.ModuleList([nn.GRU(self.embd_size, h_emb, bidirectional=True, dropout=0.2) for _ in range(2)])\n",
    "        \n",
    "    def forward(self, context, query):\n",
    "        x = self.embd(context) # (N, JX, d)\n",
    "        q_x = self.embd(query) # (N, JQ, d)\n",
    "        q, _h = self.ctx_birnn[0](q_x) # (N, JQ, d)\n",
    "        q = q.sum(1).unsqueeze(2) # (N, d, 1)\n",
    "\n",
    "        for i in range(2):\n",
    "#             print('hop', i)\n",
    "            d, _h = self.ctx_birnn[i](x) # (N, JX, d)\n",
    "        \n",
    "            attn = F.softmax(torch.bmm(d, q).squeeze()) # (N, JX)\n",
    "            attn_q = torch.bmm(attn.unsqueeze(2), q.transpose(2, 1)) # (N, JX, d)\n",
    "            x = d * attn_q # (N, JX, d)\n",
    "#             print('x', x.size())\n",
    "        return F.log_softmax(x.sum(2))\n",
    "from process_data import save_pickle, load_pickle, load_task, load_glove_weights, to_var, make_word_vector, make_one_hot\n",
    "        \n",
    "def train(model, optimizer, loss_fn, n_epoch=1, batch_size=16):\n",
    "    for epoch in range(n_epoch):\n",
    "        print('---Epoch', epoch)\n",
    "        for i in range(0, len(data)-batch_size, batch_size): # TODO shuffle, last elms\n",
    "            batch_data = data[i:i+batch_size]\n",
    "            c = [d[0] for d in batch_data]\n",
    "            q = [d[2] for d in batch_data]\n",
    "            context_var = make_word_vector(c, w2i, ctx_sent_maxlen)\n",
    "            query_var = make_word_vector(q, w2i, query_sent_maxlen)\n",
    "            labels = [d[4][0] for d in batch_data]\n",
    "#             print(labels.size())\n",
    "            labels = to_var(torch.LongTensor(labels))#.squeeze()) #\n",
    "#             labels = make_one_hot(labels, args.ctx_maxlen\n",
    "            print(labels.size())\n",
    "            outs = model(context_var, query_var)\n",
    "#             print('out', outs.size())\n",
    "            loss = loss_fn(outs, labels)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, preds = torch.max(outs, 1)\n",
    "#             print(preds)\n",
    "#             for pred, label in zip(preds, labels):\n",
    "#                 print(pred.data[0])\n",
    "#                 print(label)\n",
    "#                 print(pred.data[0] == label)\n",
    "#                 break\n",
    "            break\n",
    "        break\n",
    "            \n",
    "#             model.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "    \n",
    "model = JNet(args)\n",
    "# if torch.cuda.is_available():\n",
    "#     model.cuda()\n",
    "# print(model)\n",
    "# for p in model.parameters():\n",
    "#     print(p)\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adadelta(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=0.5, weight_decay=0.999)\n",
    "train(model, optimizer, loss_fn)\n",
    "print('fin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
